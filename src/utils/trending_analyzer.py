"""
Trending Video Analyzer
Analyzes viral video patterns from configurable time ranges
"""

import os
import json
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass

from .logging_config import get_logger
from config.config import settings

logger = get_logger(__name__)

@dataclass
class TrendingVideo:
    """Represents a trending video"""
    title: str
    views: int
    likes: int
    shares: int
    duration: int
    category: str
    platform: str
    created_at: datetime
    engagement_rate: float
    viral_score: float

@dataclass
class TrendingAnalysis:
    """Trending analysis results"""
    time_range_hours: int
    total_videos_analyzed: int
    top_categories: List[str]
    viral_patterns: List[str]
    recommended_topics: List[str]
    optimal_posting_times: List[str]
    engagement_metrics: Dict[str, float]
    platform_insights: Dict[str, Dict]
    duration_analysis: Dict[str, float]
    voice_trends: Dict[str, float]

class TrendingAnalyzer:
    """Analyzes trending videos and viral patterns"""
    
    def __init__(self):
        self.cache_dir = "trending_cache"
        os.makedirs(self.cache_dir, exist_ok=True)
        
    def analyze_trending_videos(self, hours_back: int = 24) -> TrendingAnalysis:
        """Analyze trending videos from specified hours back"""
        logger.info(f"ðŸ” Analyzing trending videos from last {hours_back} hours")
        
        try:
            # Get cutoff time
            cutoff_time = datetime.now() - timedelta(hours=hours_back)
            
            # Fetch trending videos (mock implementation for now)
            trending_videos = self._fetch_trending_videos(cutoff_time, hours_back)
            
            # Analyze patterns
            analysis = self._analyze_patterns(trending_videos, hours_back)
            
            logger.info(f"âœ… Analyzed {len(trending_videos)} trending videos")
            return analysis
            
        except Exception as e:
            logger.error(f"âŒ Error analyzing trending videos: {e}")
            return self._get_fallback_analysis(hours_back)
    
    def _fetch_trending_videos(self, cutoff_time: datetime, hours_back: int) -> List[TrendingVideo]:
        """Fetch trending videos from various platforms"""
        
        # Mock data for demonstration (replace with real API calls)
        mock_videos = []
        
        # Generate realistic mock data
        categories = ["Comedy", "Educational", "Entertainment", "Tech", "News"]
        platforms = ["youtube", "tiktok", "instagram", "twitter"]
        
        for i in range(150):  # Mock 150 videos
            video = TrendingVideo(
                title=f"Viral Video {i+1}",
                views=self._generate_realistic_views(),
                likes=self._generate_realistic_likes(),
                shares=self._generate_realistic_shares(),
                duration=self._generate_realistic_duration(),
                category=categories[i % len(categories)],
                platform=platforms[i % len(platforms)],
                created_at=cutoff_time + timedelta(hours=i * hours_back / 150),
                engagement_rate=0.0,  # Will calculate
                viral_score=0.0       # Will calculate
            )
            
            # Calculate engagement metrics
            video.engagement_rate = (video.likes + video.shares) / max(video.views, 1) * 100
            video.viral_score = self._calculate_viral_score(video)
            
            mock_videos.append(video)
        
        # Sort by viral score
        mock_videos.sort(key=lambda x: x.viral_score, reverse=True)
        
        return mock_videos
    
    def _generate_realistic_views(self) -> int:
        """Generate realistic view counts"""
        import random
        # Weighted distribution favoring viral content
        if random.random() < 0.1:  # 10% mega viral
            return random.randint(500000, 2000000)
        elif random.random() < 0.3:  # 30% highly viral
            return random.randint(100000, 500000)
        else:  # 60% moderately viral
            return random.randint(10000, 100000)
    
    def _generate_realistic_likes(self) -> int:
        """Generate realistic like counts (typically 3-8% of views)"""
        import random
        views = self._generate_realistic_views()
        like_rate = random.uniform(0.03, 0.08)
        return int(views * like_rate)
    
    def _generate_realistic_shares(self) -> int:
        """Generate realistic share counts (typically 0.5-2% of views)"""
        import random
        views = self._generate_realistic_views()
        share_rate = random.uniform(0.005, 0.02)
        return int(views * share_rate)
    
    def _generate_realistic_duration(self) -> int:
        """Generate realistic video durations"""
        import random
        # Weighted towards shorter content
        if random.random() < 0.4:  # 40% ultra-short (5-20s)
            return random.randint(5, 20)
        elif random.random() < 0.7:  # 30% short (21-60s)
            return random.randint(21, 60)
        else:  # 30% medium (61-180s)
            return random.randint(61, 180)
    
    def _calculate_viral_score(self, video: TrendingVideo) -> float:
        """Calculate viral score based on multiple factors"""
        
        # Base score from engagement rate
        score = video.engagement_rate * 10
        
        # Duration bonus (shorter videos tend to be more viral)
        if video.duration <= 15:
            score *= 1.4
        elif video.duration <= 30:
            score *= 1.2
        elif video.duration <= 60:
            score *= 1.0
        else:
            score *= 0.8
        
        # Platform multipliers
        platform_multipliers = {
            "tiktok": 1.3,
            "instagram": 1.2,
            "youtube": 1.1,
            "twitter": 1.0
        }
        score *= platform_multipliers.get(video.platform, 1.0)
        
        # Category bonuses
        category_bonuses = {
            "Comedy": 1.3,
            "Entertainment": 1.2,
            "Tech": 1.1,
            "Educational": 1.0,
            "News": 0.9
        }
        score *= category_bonuses.get(video.category, 1.0)
        
        return min(score, 100.0)  # Cap at 100
    
    def _analyze_patterns(self, videos: List[TrendingVideo], hours_back: int) -> TrendingAnalysis:
        """Analyze patterns in trending videos"""
        
        if not videos:
            return self._get_fallback_analysis(hours_back)
        
        # Category analysis
        category_counts = {}
        for video in videos:
            category_counts[video.category] = category_counts.get(video.category, 0) + 1
        
        top_categories = sorted(category_counts.keys(), key=lambda x: category_counts[x], reverse=True)[:3]
        
        # Duration analysis
        short_videos = [v for v in videos if v.duration <= 15]
        medium_videos = [v for v in videos if 16 <= v.duration <= 60]
        long_videos = [v for v in videos if v.duration > 60]
        
        duration_analysis = {
            "ultra_short_performance": sum(v.viral_score for v in short_videos) / max(len(short_videos), 1),
            "short_performance": sum(v.viral_score for v in medium_videos) / max(len(medium_videos), 1),
            "long_performance": sum(v.viral_score for v in long_videos) / max(len(long_videos), 1),
            "optimal_duration": self._find_optimal_duration(videos)
        }
        
        # Platform insights
        platform_insights = {}
        for platform in ["youtube", "tiktok", "instagram", "twitter"]:
            platform_videos = [v for v in videos if v.platform == platform]
            if platform_videos:
                platform_insights[platform] = {
                    "count": len(platform_videos),
                    "avg_viral_score": sum(v.viral_score for v in platform_videos) / len(platform_videos),
                    "avg_duration": sum(v.duration for v in platform_videos) / len(platform_videos),
                    "top_category": self._get_top_category(platform_videos)
                }
        
        # Generate insights
        viral_patterns = self._generate_viral_patterns(videos, duration_analysis)
        recommended_topics = self._generate_recommended_topics(videos, top_categories)
        optimal_times = self._analyze_posting_times(videos)
        
        # Calculate aggregate metrics
        total_views = sum(v.views for v in videos)
        total_likes = sum(v.likes for v in videos)
        total_shares = sum(v.shares for v in videos)
        
        engagement_metrics = {
            "average_views": total_views / len(videos),
            "average_likes": total_likes / len(videos),
            "average_shares": total_shares / len(videos),
            "average_engagement_rate": sum(v.engagement_rate for v in videos) / len(videos),
            "average_viral_score": sum(v.viral_score for v in videos) / len(videos)
        }
        
        # Voice trends (mock data based on current trends)
        voice_trends = {
            "neural_voices_performance": 85.2,
            "human_voices_performance": 78.4,
            "ai_voices_growth": 25.3,
            "multi_voice_content_boost": 30.1
        }
        
        return TrendingAnalysis(
            time_range_hours=hours_back,
            total_videos_analyzed=len(videos),
            top_categories=top_categories,
            viral_patterns=viral_patterns,
            recommended_topics=recommended_topics,
            optimal_posting_times=optimal_times,
            engagement_metrics=engagement_metrics,
            platform_insights=platform_insights,
            duration_analysis=duration_analysis,
            voice_trends=voice_trends
        )
    
    def _find_optimal_duration(self, videos: List[TrendingVideo]) -> int:
        """Find the optimal video duration based on viral scores"""
        duration_scores = {}
        
        for video in videos:
            duration_bucket = (video.duration // 5) * 5  # Group by 5-second buckets
            if duration_bucket not in duration_scores:
                duration_scores[duration_bucket] = []
            duration_scores[duration_bucket].append(video.viral_score)
        
        # Find duration with highest average viral score
        best_duration = 15  # Default
        best_score = 0
        
        for duration, scores in duration_scores.items():
            avg_score = sum(scores) / len(scores)
            if avg_score > best_score:
                best_score = avg_score
                best_duration = duration
        
        return best_duration
    
    def _get_top_category(self, videos: List[TrendingVideo]) -> str:
        """Get the top category for a list of videos"""
        category_counts = {}
        for video in videos:
            category_counts[video.category] = category_counts.get(video.category, 0) + 1
        
        return max(category_counts.keys(), key=lambda x: category_counts[x]) if category_counts else "Unknown"
    
    def _generate_viral_patterns(self, videos: List[TrendingVideo], duration_analysis: Dict) -> List[str]:
        """Generate insights about viral patterns"""
        patterns = []
        
        # Duration insights
        if duration_analysis["ultra_short_performance"] > duration_analysis["long_performance"]:
            improvement = ((duration_analysis["ultra_short_performance"] - duration_analysis["long_performance"]) / 
                          duration_analysis["long_performance"] * 100)
            patterns.append(f"Ultra-short videos (â‰¤15s) perform {improvement:.0f}% better than longer content")
        
        # AI content trends
        patterns.append("AI-generated content engagement up 25% in the last week")
        patterns.append("Multi-voice audio increases retention by 30%")
        patterns.append("Neural voice synthesis preferred over robotic TTS by 85%")
        
        # Platform-specific insights
        top_videos = sorted(videos, key=lambda x: x.viral_score, reverse=True)[:10]
        if len([v for v in top_videos if v.platform == "tiktok"]) >= 5:
            patterns.append("TikTok dominates viral content with 50%+ of top performers")
        
        return patterns
    
    def _generate_recommended_topics(self, videos: List[TrendingVideo], top_categories: List[str]) -> List[str]:
        """Generate recommended topics based on trends"""
        
        # Base recommendations on top categories
        topic_suggestions = {
            "Comedy": [
                "AI technology humor and fails",
                "Behind-the-scenes AI creation comedy",
                "Human vs AI funny comparisons"
            ],
            "Educational": [
                "Quick AI explainers (15-second format)",
                "AI tool tutorials and tips",
                "Future of AI predictions"
            ],
            "Entertainment": [
                "AI-generated entertainment content",
                "Virtual performances and shows",
                "Interactive AI experiences"
            ],
            "Tech": [
                "Latest AI breakthrough demonstrations",
                "AI tool reviews and comparisons",
                "Tech prediction and analysis"
            ],
            "News": [
                "AI industry news and updates",
                "Technology impact stories",
                "Innovation announcements"
            ]
        }
        
        recommendations = []
        for category in top_categories:
            if category in topic_suggestions:
                recommendations.extend(topic_suggestions[category])
        
        return recommendations[:5]  # Top 5 recommendations
    
    def _analyze_posting_times(self, videos: List[TrendingVideo]) -> List[str]:
        """Analyze optimal posting times"""
        
        # Mock optimal times based on general social media trends
        return ["12:00 PM", "6:00 PM", "9:00 PM"]
    
    def _get_fallback_analysis(self, hours_back: int) -> TrendingAnalysis:
        """Get fallback analysis when real data is unavailable"""
        
        return TrendingAnalysis(
            time_range_hours=hours_back,
            total_videos_analyzed=0,
            top_categories=["Comedy", "Educational", "Entertainment"],
            viral_patterns=[
                "Unable to fetch real-time data",
                "Using cached trending patterns",
                "15-second videos typically perform best"
            ],
            recommended_topics=[
                "AI technology demonstrations",
                "Quick educational content",
                "Comedy and entertainment"
            ],
            optimal_posting_times=["12:00 PM", "6:00 PM", "9:00 PM"],
            engagement_metrics={
                "average_views": 0,
                "average_likes": 0,
                "average_shares": 0,
                "average_engagement_rate": 0,
                "average_viral_score": 0
            },
            platform_insights={},
            duration_analysis={
                "ultra_short_performance": 0,
                "short_performance": 0,
                "long_performance": 0,
                "optimal_duration": 15
            },
            voice_trends={
                "neural_voices_performance": 85.0,
                "human_voices_performance": 75.0,
                "ai_voices_growth": 25.0,
                "multi_voice_content_boost": 30.0
            }
        )

def analyze_trending_content(hours_back: int = 24) -> TrendingAnalysis:
    """Convenience function to analyze trending content"""
    analyzer = TrendingAnalyzer()
    return analyzer.analyze_trending_videos(hours_back) 