#!/usr/bin/env python3
"""Demo News Aggregator - Simulated Example"""

import asyncio
from datetime import datetime
import random

# Mock data for demonstration
MOCK_YNET_ARTICLES = [
    {
        "title": "×¨××© ×”×××©×œ×” × ×¤×’×© ×¢× × ×©×™× ××¨×”×´×‘ ×œ×“×™×•×Ÿ ×‘× ×•×©××™ ×‘×™×˜×—×•×Ÿ",
        "content": "×”×¤×’×™×©×” ×”×ª×§×™×™××” ×‘×‘×™×ª ×”×œ×‘×Ÿ ×•×¢×¡×§×” ×‘× ×•×©××™ ×‘×™×˜×—×•×Ÿ ××–×•×¨×™×™×...",
        "url": "https://www.ynet.co.il/news/article/1",
        "published": datetime.now(),
        "media": ["https://ynet.co.il/image1.jpg", "https://ynet.co.il/video1.mp4"]
    },
    {
        "title": "×’×™×œ×•×™ ××¨×›×™××•×œ×•×’×™ ××¨×¢×™×© ×‘×™×¨×•×©×œ×™×",
        "content": "××¨×›×™××•×œ×•×’×™× ×’×™×œ×• ×××¦× × ×“×™×¨ ××ª×§×•×¤×ª ×‘×™×ª ×©× ×™...",
        "url": "https://www.ynet.co.il/news/article/2",
        "published": datetime.now(),
        "media": ["https://ynet.co.il/image2.jpg"]
    },
    {
        "title": "××›×‘×™ ×ª×œ ××‘×™×‘ × ×™×¦×—×” ×‘×“×¨××” ××ª ×”×¤×•×¢×œ",
        "content": "×‘××©×—×§ ××¨×ª×§ ×©×”×•×›×¨×¢ ×‘×“×§×•×ª ×”××—×¨×•× ×•×ª...",
        "url": "https://www.ynet.co.il/sports/article/3",
        "published": datetime.now(),
        "media": ["https://ynet.co.il/sports_video.mp4"]
    }
]

MOCK_CNN_ARTICLES = [
    {
        "title": "Breaking: Major Climate Summit Reaches Historic Agreement",
        "content": "World leaders have agreed on unprecedented measures to combat climate change...",
        "url": "https://www.cnn.com/article/1",
        "published": datetime.now(),
        "media": ["https://cnn.com/climate_image.jpg"]
    },
    {
        "title": "Tech Giant Announces Revolutionary AI Breakthrough",
        "content": "A major technology company unveiled its latest artificial intelligence system...",
        "url": "https://www.cnn.com/tech/article/2",
        "published": datetime.now(),
        "media": ["https://cnn.com/tech_video.mp4", "https://cnn.com/ai_diagram.jpg"]
    },
    {
        "title": "Stock Markets Reach All-Time Highs Amid Economic Recovery",
        "content": "Global markets showed strong performance as economic indicators improve...",
        "url": "https://www.cnn.com/business/article/3",
        "published": datetime.now(),
        "media": ["https://cnn.com/markets_chart.jpg"]
    }
]

class MockNewsAggregator:
    """Mock news aggregator for demonstration"""
    
    async def create_news_edition(self, sources, edition_type="general", duration=5):
        """Create a simulated news edition"""
        
        print(f"\nğŸ¬ Creating {edition_type} News Edition")
        print(f"ğŸ“° Sources: {', '.join(sources)}")
        print(f"â±ï¸  Duration: {duration} minutes")
        print("\n" + "="*60 + "\n")
        
        # Step 1: Scraping
        print("ğŸ“¡ STEP 1: Scraping News Sources...")
        all_articles = []
        
        for source in sources:
            if "ynet" in source:
                print(f"   ğŸ‡®ğŸ‡± Scraping {source}...")
                await asyncio.sleep(0.5)  # Simulate network delay
                articles = MOCK_YNET_ARTICLES
                all_articles.extend(articles)
                print(f"      âœ“ Found {len(articles)} Hebrew articles")
                
            elif "cnn" in source:
                print(f"   ğŸ‡ºğŸ‡¸ Scraping {source}...")
                await asyncio.sleep(0.5)  # Simulate network delay
                articles = MOCK_CNN_ARTICLES
                all_articles.extend(articles)
                print(f"      âœ“ Found {len(articles)} English articles")
        
        print(f"\n   ğŸ“Š Total articles collected: {len(all_articles)}")
        
        # Step 2: Analyzing Content
        print("\nğŸ¤– STEP 2: Analyzing Content with AI...")
        await asyncio.sleep(1)  # Simulate AI processing
        
        for i, article in enumerate(all_articles):
            article["relevance_score"] = random.uniform(0.6, 0.95)
            article["sentiment"] = random.choice(["positive", "neutral", "negative"])
            article["categories"] = random.sample(["politics", "tech", "sports", "culture", "business"], 2)
            
        print("   âœ“ Content analysis complete")
        print("   âœ“ Relevance scores calculated")
        print("   âœ“ Sentiment analysis done")
        
        # Step 3: Grouping Related News
        print("\nğŸ”— STEP 3: Grouping Related Stories...")
        await asyncio.sleep(0.5)
        
        # Mock grouping
        groups = [
            {
                "name": "International Politics",
                "articles": [a for a in all_articles if "politics" in a.get("categories", [])],
                "importance": "high"
            },
            {
                "name": "Technology & Innovation",
                "articles": [a for a in all_articles if "tech" in a.get("categories", [])],
                "importance": "medium"
            },
            {
                "name": "Sports & Entertainment",
                "articles": [a for a in all_articles if "sports" in a.get("categories", [])],
                "importance": "low"
            }
        ]
        
        print(f"   âœ“ Created {len(groups)} story groups")
        for group in groups:
            print(f"      â€¢ {group['name']}: {len(group['articles'])} stories")
        
        # Step 4: AI Agent Discussions
        print("\nğŸ§  STEP 4: AI Agent Discussions...")
        await asyncio.sleep(1)
        
        print("   ğŸ‘¥ Agent Panel: Reporter, Analyst, Editor, Producer")
        print("   ğŸ’¬ Discussion Topics:")
        print("      â€¢ Lead story selection")
        print("      â€¢ Story ordering and flow")
        print("      â€¢ Visual presentation strategy")
        print("   âœ“ Consensus reached on editorial decisions")
        
        # Step 5: Downloading Media
        print("\nğŸ“¥ STEP 5: Downloading Media Assets...")
        media_count = sum(len(article.get("media", [])) for article in all_articles)
        
        for i in range(min(media_count, 10)):
            await asyncio.sleep(0.2)
            print(f"   â¬‡ï¸  Downloading media {i+1}/{media_count}...")
        
        print(f"   âœ“ Downloaded {media_count} media files")
        print("   âœ“ 8 images, 4 videos processed")
        
        # Step 6: Creating Video Composition
        print("\nğŸ¨ STEP 6: Creating Video Composition...")
        await asyncio.sleep(1)
        
        print("   ğŸ“‹ Script Structure:")
        print("      â€¢ Intro (5 seconds)")
        print("      â€¢ Story 1: International Politics (45 seconds)")
        print("      â€¢ Story 2: Tech Breakthrough (40 seconds)")
        print("      â€¢ Story 3: Sports Update (30 seconds)")
        print("      â€¢ Outro (5 seconds)")
        print(f"   â±ï¸  Total Duration: {duration} minutes")
        
        # Step 7: Generating Video
        print("\nğŸ¥ STEP 7: Generating Final Video...")
        print("   ğŸ™ï¸ Adding narration...")
        await asyncio.sleep(0.5)
        print("   ğŸ–¼ï¸ Composing visuals with scraped media...")
        await asyncio.sleep(0.5)
        print("   ğŸµ Adding background music...")
        await asyncio.sleep(0.5)
        print("   âœ¨ Applying transitions and effects...")
        await asyncio.sleep(0.5)
        
        # Final output
        output_path = f"outputs/news_edition_{edition_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4"
        
        print("\n" + "="*60)
        print(f"\nâœ… NEWS EDITION CREATED SUCCESSFULLY!")
        print(f"ğŸ“¹ Output: {output_path}")
        print(f"ğŸ“Š Stats:")
        print(f"   â€¢ Total stories: {len(all_articles)}")
        print(f"   â€¢ Languages: Hebrew, English")
        print(f"   â€¢ Media used: {media_count} assets")
        print(f"   â€¢ Duration: {duration} minutes")
        print(f"   â€¢ Style: Professional news broadcast")
        
        return output_path

async def main():
    """Demo the news aggregator"""
    
    print("ğŸ¬ NEWS AGGREGATOR DEMO")
    print("=" * 60)
    print("This demonstrates how the news aggregator works:")
    print("1. Scrapes news from multiple sources")
    print("2. Analyzes content with AI")
    print("3. Groups related stories")
    print("4. Uses AI agents for editorial decisions")
    print("5. Downloads actual media from sources")
    print("6. Creates professional news video")
    print("=" * 60)
    
    aggregator = MockNewsAggregator()
    
    # Demo 1: Ynet + CNN aggregation
    await aggregator.create_news_edition(
        sources=["https://www.ynet.co.il", "https://www.cnn.com"],
        edition_type="general",
        duration=5
    )

if __name__ == "__main__":
    asyncio.run(main())