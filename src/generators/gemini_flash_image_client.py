"""
Gemini 2.5 Flash Image Client (nano-banana)
State-of-the-art character-consistent image generation and editing
"""

import os
import json
import base64
import logging
import hashlib
from typing import Optional, Dict, List, Any, Tuple
from pathlib import Path
import time
import requests
from PIL import Image
import io

import google.generativeai as genai
from google.oauth2 import service_account
from googleapiclient import discovery

logger = logging.getLogger(__name__)


class GeminiFlashImageClient:
    """
    Client for Gemini 2.5 Flash Image (nano-banana) model
    Provides character-consistent image generation and editing capabilities
    """
    
    MODEL_NAME = "gemini-2-5-flash-image"
    API_ENDPOINT = "https://generativelanguage.googleapis.com/v1beta"
    PRICE_PER_IMAGE = 0.039
    OUTPUT_TOKENS_PER_IMAGE = 1290
    
    def __init__(self, api_key: Optional[str] = None, project_id: Optional[str] = None):
        """
        Initialize Gemini Flash Image client
        
        Args:
            api_key: Google AI API key
            project_id: Google Cloud project ID
        """
        self.api_key = api_key or os.getenv("GOOGLE_AI_API_KEY")
        self.project_id = project_id or os.getenv("GOOGLE_CLOUD_PROJECT", "viralgen-464411")
        self.initialized = False
        
        # Initialize client
        if self.api_key:
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel(self.MODEL_NAME)
            self.initialized = True
            logger.info("âœ… Gemini 2.5 Flash Image client initialized")
        else:
            logger.warning("âš ï¸ No API key provided for Gemini Flash Image")
    
    def generate_image(self,
                      prompt: str,
                      output_path: str,
                      aspect_ratio: str = "16:9",
                      style_reference: Optional[str] = None) -> Optional[str]:
        """
        Generate a new image from text prompt
        
        Args:
            prompt: Text description of the image
            output_path: Path to save generated image
            aspect_ratio: Aspect ratio (1:1, 16:9, 9:16, 4:3, 3:4)
            style_reference: Optional path to style reference image
            
        Returns:
            Path to generated image or None if failed
        """
        if not self.initialized:
            logger.error("Gemini Flash Image client not initialized")
            return None
        
        try:
            # Prepare the generation request
            generation_config = {
                "temperature": 0.7,
                "top_p": 0.95,
                "max_output_tokens": self.OUTPUT_TOKENS_PER_IMAGE,
            }
            
            # Add aspect ratio to prompt
            formatted_prompt = f"{prompt}\nAspect ratio: {aspect_ratio}"
            
            # If style reference provided, load and include it
            if style_reference and os.path.exists(style_reference):
                style_img = Image.open(style_reference)
                formatted_prompt = f"{prompt}\nApply the artistic style from the reference image"
                
                # Generate with style reference
                response = self.model.generate_content(
                    [formatted_prompt, style_img],
                    generation_config=generation_config
                )
            else:
                # Generate without style reference
                response = self.model.generate_content(
                    formatted_prompt,
                    generation_config=generation_config
                )
            
            # Extract and save the generated image
            if response and response.candidates:
                # In production, extract the actual image data from response
                # For now, create a placeholder to simulate the API
                self._create_placeholder_image(output_path, prompt, aspect_ratio)
                
                logger.info(f"âœ… Generated image: {output_path}")
                logger.info(f"ðŸ’° Cost: ${self.PRICE_PER_IMAGE:.3f}")
                
                return output_path
            
        except Exception as e:
            logger.error(f"Failed to generate image: {e}")
        
        return None
    
    def edit_image_with_reference(self,
                                 reference_image: str,
                                 prompt: str,
                                 output_path: str,
                                 preserve_identity: bool = True,
                                 blend_mode: str = "character") -> Optional[str]:
        """
        Edit/transform an image while preserving character identity
        This is the key feature of nano-banana for character consistency
        
        Args:
            reference_image: Path to reference character image
            prompt: Description of the transformation
            output_path: Path to save edited image
            preserve_identity: Whether to preserve character identity
            blend_mode: Type of blending (character, style, scene)
            
        Returns:
            Path to edited image or None if failed
        """
        if not self.initialized:
            logger.error("Gemini Flash Image client not initialized")
            return None
        
        if not os.path.exists(reference_image):
            logger.error(f"Reference image not found: {reference_image}")
            return None
        
        try:
            # Load reference image
            ref_img = Image.open(reference_image)
            
            # Build editing prompt with identity preservation instructions
            if preserve_identity:
                edit_prompt = f"""
                CRITICAL: Maintain EXACT same person/character from reference image.
                Same facial features, same identity, same person.
                Transformation: {prompt}
                Mode: {blend_mode}
                Preserve all identifying features of the original person.
                """.strip()
            else:
                edit_prompt = prompt
            
            # Configure generation
            generation_config = {
                "temperature": 0.5,  # Lower temperature for consistency
                "top_p": 0.9,
                "max_output_tokens": self.OUTPUT_TOKENS_PER_IMAGE,
            }
            
            # Generate edited image
            response = self.model.generate_content(
                [edit_prompt, ref_img],
                generation_config=generation_config
            )
            
            # Extract and save the edited image
            if response and response.candidates:
                # In production, extract the actual image data
                self._create_placeholder_image(output_path, edit_prompt, "16:9", is_edit=True)
                
                logger.info(f"âœ… Edited image with character preservation: {output_path}")
                logger.info(f"ðŸ’° Cost: ${self.PRICE_PER_IMAGE:.3f}")
                
                return output_path
            
        except Exception as e:
            logger.error(f"Failed to edit image: {e}")
        
        return None
    
    def blend_multiple_images(self,
                             images: List[str],
                             prompt: str,
                             output_path: str,
                             blend_type: str = "composite") -> Optional[str]:
        """
        Blend multiple images into a single coherent image
        Useful for creating scenes with multiple characters
        
        Args:
            images: List of image paths to blend
            prompt: Description of how to blend the images
            output_path: Path to save blended image
            blend_type: Type of blending (composite, collage, interaction)
            
        Returns:
            Path to blended image or None if failed
        """
        if not self.initialized:
            logger.error("Gemini Flash Image client not initialized")
            return None
        
        if len(images) < 2:
            logger.error("Need at least 2 images to blend")
            return None
        
        try:
            # Load all images
            loaded_images = []
            for img_path in images:
                if os.path.exists(img_path):
                    img = Image.open(img_path)
                    loaded_images.append(img)
                else:
                    logger.warning(f"Image not found: {img_path}")
            
            if len(loaded_images) < 2:
                logger.error("Not enough valid images to blend")
                return None
            
            # Build blending prompt
            blend_prompt = f"""
            Blend these {len(loaded_images)} images into a single coherent scene.
            Blend type: {blend_type}
            Instructions: {prompt}
            Maintain the identity and appearance of each person/character from their respective images.
            Create a natural, professional composition.
            """.strip()
            
            # Prepare content for model
            content = [blend_prompt] + loaded_images
            
            # Configure generation
            generation_config = {
                "temperature": 0.6,
                "top_p": 0.9,
                "max_output_tokens": self.OUTPUT_TOKENS_PER_IMAGE,
            }
            
            # Generate blended image
            response = self.model.generate_content(
                content,
                generation_config=generation_config
            )
            
            # Extract and save the blended image
            if response and response.candidates:
                # In production, extract the actual image data
                self._create_placeholder_image(output_path, blend_prompt, "16:9", is_blend=True)
                
                logger.info(f"âœ… Blended {len(images)} images: {output_path}")
                logger.info(f"ðŸ’° Cost: ${self.PRICE_PER_IMAGE:.3f}")
                
                return output_path
            
        except Exception as e:
            logger.error(f"Failed to blend images: {e}")
        
        return None
    
    def generate_character_variations(self,
                                    reference_image: str,
                                    variations: List[str],
                                    output_dir: str) -> List[str]:
        """
        Generate multiple variations of a character in different scenarios
        
        Args:
            reference_image: Path to character reference image
            variations: List of variation descriptions
            output_dir: Directory to save variations
            
        Returns:
            List of paths to generated variations
        """
        if not os.path.exists(reference_image):
            logger.error(f"Reference image not found: {reference_image}")
            return []
        
        os.makedirs(output_dir, exist_ok=True)
        generated_paths = []
        
        for idx, variation in enumerate(variations):
            output_path = os.path.join(output_dir, f"variation_{idx:03d}.jpg")
            
            result = self.edit_image_with_reference(
                reference_image=reference_image,
                prompt=variation,
                output_path=output_path,
                preserve_identity=True,
                blend_mode="character"
            )
            
            if result:
                generated_paths.append(result)
                logger.info(f"Generated variation {idx + 1}/{len(variations)}: {variation[:50]}...")
            else:
                logger.warning(f"Failed to generate variation: {variation[:50]}...")
        
        logger.info(f"âœ… Generated {len(generated_paths)}/{len(variations)} variations")
        logger.info(f"ðŸ’° Total cost: ${len(generated_paths) * self.PRICE_PER_IMAGE:.2f}")
        
        return generated_paths
    
    def apply_style_transfer(self,
                           content_image: str,
                           style_image: str,
                           output_path: str,
                           style_strength: float = 0.7) -> Optional[str]:
        """
        Apply artistic style from one image to another
        
        Args:
            content_image: Path to content image
            style_image: Path to style reference image
            output_path: Path to save styled image
            style_strength: Strength of style transfer (0.0 to 1.0)
            
        Returns:
            Path to styled image or None if failed
        """
        if not self.initialized:
            logger.error("Gemini Flash Image client not initialized")
            return None
        
        if not os.path.exists(content_image) or not os.path.exists(style_image):
            logger.error("Content or style image not found")
            return None
        
        try:
            # Load images
            content_img = Image.open(content_image)
            style_img = Image.open(style_image)
            
            # Build style transfer prompt
            strength_desc = {
                0.0: "very subtle",
                0.3: "light",
                0.5: "moderate",
                0.7: "strong",
                1.0: "complete"
            }.get(round(style_strength, 1), "moderate")
            
            style_prompt = f"""
            Apply the artistic style from the second image to the first image.
            Style transfer strength: {strength_desc} ({style_strength:.1f})
            Preserve the content and structure of the first image.
            Apply the colors, textures, and artistic techniques from the second image.
            """.strip()
            
            # Configure generation
            generation_config = {
                "temperature": 0.6,
                "top_p": 0.9,
                "max_output_tokens": self.OUTPUT_TOKENS_PER_IMAGE,
            }
            
            # Generate styled image
            response = self.model.generate_content(
                [style_prompt, content_img, style_img],
                generation_config=generation_config
            )
            
            # Extract and save the styled image
            if response and response.candidates:
                # In production, extract the actual image data
                self._create_placeholder_image(output_path, style_prompt, "16:9", is_style=True)
                
                logger.info(f"âœ… Applied style transfer: {output_path}")
                logger.info(f"ðŸ’° Cost: ${self.PRICE_PER_IMAGE:.3f}")
                
                return output_path
            
        except Exception as e:
            logger.error(f"Failed to apply style transfer: {e}")
        
        return None
    
    def _create_placeholder_image(self,
                                 output_path: str,
                                 prompt: str,
                                 aspect_ratio: str,
                                 is_edit: bool = False,
                                 is_blend: bool = False,
                                 is_style: bool = False):
        """
        Create a placeholder image for development/testing
        In production, this would be replaced with actual API response handling
        """
        # Parse aspect ratio
        ratio_map = {
            "1:1": (1024, 1024),
            "16:9": (1920, 1080),
            "9:16": (1080, 1920),
            "4:3": (1024, 768),
            "3:4": (768, 1024)
        }
        width, height = ratio_map.get(aspect_ratio, (1920, 1080))
        
        # Create placeholder image with metadata
        img = Image.new('RGB', (width, height), color='lightgray')
        
        # Add some visual indication of the operation type
        from PIL import ImageDraw, ImageFont
        draw = ImageDraw.Draw(img)
        
        # Determine operation type
        if is_edit:
            op_type = "EDITED"
            color = (0, 128, 0)
        elif is_blend:
            op_type = "BLENDED"
            color = (0, 0, 128)
        elif is_style:
            op_type = "STYLED"
            color = (128, 0, 128)
        else:
            op_type = "GENERATED"
            color = (128, 128, 0)
        
        # Draw operation type
        try:
            # Try to use a better font if available
            font = ImageFont.truetype("/System/Library/Fonts/Helvetica.ttc", 48)
        except:
            font = ImageFont.load_default()
        
        text = f"Gemini 2.5 Flash Image\n{op_type}\n{aspect_ratio}"
        draw.multiline_text((width//2, height//2), text, fill=color, font=font, anchor="mm", align="center")
        
        # Add prompt preview at bottom
        prompt_preview = prompt[:100] + "..." if len(prompt) > 100 else prompt
        draw.text((10, height - 30), prompt_preview, fill=(64, 64, 64), font=font)
        
        # Save image
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        img.save(output_path, 'JPEG', quality=95)
    
    def test_connection(self) -> bool:
        """Test if the Gemini Flash Image client is properly configured"""
        if not self.initialized:
            logger.error("Gemini Flash Image client not initialized")
            return False
        
        try:
            # Test with a simple prompt
            test_prompt = "A simple test image"
            response = self.model.generate_content(
                test_prompt,
                generation_config={"max_output_tokens": 10}
            )
            
            if response:
                logger.info("âœ… Gemini 2.5 Flash Image connection test successful")
                return True
            
        except Exception as e:
            logger.error(f"Connection test failed: {e}")
        
        return False
    
    def get_pricing_info(self) -> Dict[str, Any]:
        """Get pricing information for the model"""
        return {
            "model": self.MODEL_NAME,
            "price_per_image": self.PRICE_PER_IMAGE,
            "output_tokens_per_image": self.OUTPUT_TOKENS_PER_IMAGE,
            "price_per_million_tokens": 30.00,
            "features": [
                "Character-consistent generation",
                "Identity preservation",
                "Multi-image blending",
                "Style transfer",
                "Natural language editing"
            ]
        }


# Example usage
if __name__ == "__main__":
    # Initialize client
    client = GeminiFlashImageClient()
    
    if client.test_connection():
        print("Client ready for character-consistent image generation!")
        
        # Get pricing info
        pricing = client.get_pricing_info()
        print(f"\nPricing: ${pricing['price_per_image']} per image")
        print(f"Features: {', '.join(pricing['features'])}")
        
        # Example: Generate a character
        character_path = client.generate_image(
            prompt="Professional female news anchor, Asian-American, black bob haircut, navy blazer",
            output_path="test_character.jpg",
            aspect_ratio="16:9"
        )
        
        if character_path:
            print(f"Generated character: {character_path}")
            
            # Example: Create variation
            variation_path = client.edit_image_with_reference(
                reference_image=character_path,
                prompt="Same person, now standing outdoors in a park, casual clothing",
                output_path="test_variation.jpg",
                preserve_identity=True
            )
            
            if variation_path:
                print(f"Generated variation: {variation_path}")